{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird constants?\n",
    "# should probably find nicer way to use these vals\n",
    "\n",
    "HEIGHT = 1\n",
    "WIDTH = 2\n",
    "\n",
    "LEFT = 0\n",
    "RIGHT = 1\n",
    "TOP = 2\n",
    "BOTTOM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(pad_str, \n",
    "                filter_shape, \n",
    "                in_shape, \n",
    "                stride_h=1, \n",
    "                stride_w=1, \n",
    "                dilate_h=1, \n",
    "                dilate_w=1\n",
    "               ):\n",
    "    \n",
    "    padding=[0,0,0,0]\n",
    "\n",
    "    if pad_str == 'SAME':\n",
    "        dilated_width = (filter_shape[WIDTH] - 1) * dilate_w + 1\n",
    "        dilated_height = (filter_shape[HEIGHT] - 1) * dilate_h + 1\n",
    "\n",
    "        out_w = math.ceil(in_shape[WIDTH] / stride_w)\n",
    "        out_h = math.ceil(in_shape[HEIGHT] / stride_h)\n",
    "\n",
    "        padding[0] = math.floor(dilated_width / 2)\n",
    "        padding[1] = out_w * stride_w - (stride_w - 1) + math.floor(filter_shape[WIDTH] / 2) - in_shape[WIDTH]\n",
    "        padding[2] = math.floor(dilated_height / 2)\n",
    "        padding[3] = out_h * stride_h - (stride_h - 1) + math.floor(filter_shape[HEIGHT] / 2) - in_shape[HEIGHT]                \n",
    "\n",
    "    return padding\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_shape(in_shape, \n",
    "                    filter_shape, \n",
    "                    pad_str='VALID', \n",
    "                    stride_h=1, \n",
    "                    stride_w=1, \n",
    "                    dilate_h=1, \n",
    "                    dilate_w=1\n",
    "                   ):\n",
    "    w = 0\n",
    "    h = 0\n",
    "\n",
    "    if pad_str == 'SAME':\n",
    "        w = math.ceil(in_shape[WIDTH] / stride_w)\n",
    "        h = math.ceil(in_shape[HEIGHT] / stride_h)\n",
    "    else:\n",
    "        dilated_rad_h = math.floor(((filter_shape[HEIGHT] - 1) * dilate_h + 1) / 2)\n",
    "        dilated_rad_w = math.floor(((filter_shape[WIDTH] - 1) * dilate_w + 1) / 2)\n",
    "        \n",
    "        \n",
    "        w = math.floor((in_shape[WIDTH] - dilated_rad_w - 1) / stride_w)\n",
    "        h = math.floor((in_shape[HEIGHT] - dilated_rad_h - 1) / stride_h)\n",
    "\n",
    "    return (h, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data,\n",
    "           filter_shape, \n",
    "           stride_h=1, \n",
    "           stride_w=1,\n",
    "           dilate_h=1, \n",
    "           dilate_w=1,\n",
    "           pad=[0,0,0,0] # left right top bottom\n",
    "          ):\n",
    "    \n",
    "    filter_h = (filter_shape[HEIGHT]-1) * dilate_h + 1\n",
    "    filter_w = (filter_shape[WIDTH]-1) * dilate_w + 1\n",
    "    channels = input_data.shape[-1]\n",
    "    \n",
    "\n",
    "    def get_pixel(row, col):\n",
    "        if 0 <= row < input_data.shape[HEIGHT] and 0 <= col < input_data.shape[WIDTH]:\n",
    "            return input_data[0, row, col, :]\n",
    "        return np.zeros(channels)\n",
    "\n",
    "    pixels_per_col = filter_shape[1] * filter_shape[2] * filter_shape[3]\n",
    "    cols = np.empty((pixels_per_col, 0))\n",
    "    \n",
    "    \n",
    "    # loop over image\n",
    "    for r in range(-pad[TOP], input_data.shape[HEIGHT] - filter_h + 1 + pad[BOTTOM], stride_h):\n",
    "        for c in range(-pad[LEFT], input_data.shape[WIDTH] - filter_w + 1 + pad[RIGHT], stride_w):\n",
    "            \n",
    "            # loop over kernel\n",
    "            new_col = []\n",
    "            for row in range(r, r + filter_h, dilate_h):\n",
    "                for col in range(c, c + filter_w, dilate_w):\n",
    "                    \n",
    "                    for val in get_pixel(row, col):\n",
    "                        new_col.append(val)\n",
    "            new_col = np.array(new_col).reshape((-1, 1))\n",
    "            cols = np.append(cols, new_col, axis=-1)\n",
    "                    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthwise_conv(input_data, \n",
    "                   filter_weights, \n",
    "                   bias_weights=None, \n",
    "                   stride_h=1, \n",
    "                   stride_w=1, \n",
    "                   dilate_h=1, \n",
    "                   dilate_w=1, \n",
    "                   pad_str='VALID', \n",
    "                   depth_mult=1\n",
    "                  ):\n",
    "    \n",
    "    new_channel_shape = get_final_shape(input_data.shape, filter_weights.shape, pad_str, stride_h=stride_h, stride_w=stride_w)\n",
    "    padding = get_padding(pad_str, filter_weights.shape, input_data.shape, stride_h, stride_w, dilate_h, dilate_w)\n",
    "\n",
    "    # display stuff and make sure it's correct\n",
    "    print('*****DOING DEPTHWISE CONV*****')\n",
    "    print('input shape:', input_data.shape)\n",
    "    print('filter shape:', filter_weights.shape)\n",
    "    print('stride_h:', stride_h)\n",
    "    print('stride_w:', stride_w)\n",
    "    print('dilate_h_factor:', dilate_h)\n",
    "    print('dilate_w_factor:', dilate_w)\n",
    "    print('padding:', pad_str, padding)\n",
    "    print('depth mult:', depth_mult)\n",
    "    print('new channel shape:', new_channel_shape)\n",
    "    \n",
    "    \n",
    "    out = []\n",
    "    num_channels = input_data.shape[-1]\n",
    "    \n",
    "    dilated_kernel_h = filter_weights.shape[HEIGHT] * dilate_h\n",
    "    dilated_kernel_w = filter_weights.shape[WIDTH] * dilate_w\n",
    "\n",
    "    def get_val(row, col, channel):\n",
    "        if 0 <= row < input_data.shape[HEIGHT] and 0 <= col < input_data.shape[WIDTH]:\n",
    "            return input_data[0, row, col, channel]\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    for channel_idx in range(num_channels):\n",
    "        \n",
    "        # loop over channel\n",
    "        channel = input_data[:,:,:,channel_idx]\n",
    "        new_channel = []\n",
    "        for row in range(-padding[LEFT], input_data.shape[HEIGHT] - dilated_kernel_h + 1 + padding[RIGHT], stride_h):\n",
    "            for col in range(-padding[TOP], input_data.shape[WIDTH] - dilated_kernel_w + 1 + padding[BOTTOM], stride_w):\n",
    "                \n",
    "                val = 0\n",
    "                # loop over kernel\n",
    "                for r in range(0, dilated_kernel_h, dilate_h):\n",
    "                    for c in range(0, dilated_kernel_w, dilate_w):\n",
    "                        val += get_val(row + r, col + c, channel_idx) * filter_weights[0, r, c, channel_idx]\n",
    "                new_channel.append(val)\n",
    "                \n",
    "        new_channel = np.array(new_channel).reshape(new_channel_shape)\n",
    "        out.append(new_channel)\n",
    "                        \n",
    "        \n",
    "    out = np.stack(out, axis=-1)\n",
    "    out = out.reshape((1, out.shape[0], out.shape[1], out.shape[2]))\n",
    "    print('final shape:', out.shape)\n",
    "    if bias_weights is not None:\n",
    "        out = np.add(out, bias_weights)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool(input_data, \n",
    "             filter_shape, \n",
    "             stride_h=1, \n",
    "             stride_w=1, \n",
    "             pad_str='VALID', \n",
    "            ):\n",
    "    \n",
    "    f_weight = 1 / np.prod(filter_shape)\n",
    "    filter_shape = (1, filter_shape[0], filter_shape[1], input_data.shape[-1])\n",
    "    \n",
    "    new_channel_shape = get_final_shape(input_data.shape, filter_shape, pad_str, stride_h=stride_h, stride_w=stride_w)\n",
    "    padding = get_padding(pad_str, filter_shape, input_data.shape, stride_h, stride_w)\n",
    "\n",
    "    # display stuff and make sure it's correct\n",
    "    print('********DOING AVG POOL********')\n",
    "    print('input shape:', input_data.shape)\n",
    "    print('filter shape:', filter_shape)\n",
    "    print('stride_h:', stride_h)\n",
    "    print('stride_w:', stride_w)\n",
    "    print('padding:', pad_str, padding)\n",
    "    print('new channel shape:', new_channel_shape)\n",
    "    \n",
    "    \n",
    "    out = []\n",
    "    num_channels = input_data.shape[-1]\n",
    "\n",
    "    def get_val(row, col, channel):\n",
    "        if 0 <= row < input_data.shape[HEIGHT] and 0 <= col < input_data.shape[WIDTH]:\n",
    "            return input_data[0, row, col, channel]\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    for channel_idx in range(num_channels):\n",
    "        \n",
    "        # loop over channel\n",
    "        channel = input_data[:,:,:,channel_idx]\n",
    "        new_channel = []\n",
    "        for row in range(-padding[LEFT], input_data.shape[HEIGHT] - filter_shape[HEIGHT] + 1 + padding[RIGHT], stride_h):\n",
    "            for col in range(-padding[TOP], input_data.shape[WIDTH] - filter_shape[WIDTH] + 1 + padding[BOTTOM], stride_w):\n",
    "                \n",
    "                val = 0\n",
    "                # loop over kernel\n",
    "                for r in range(filter_shape[HEIGHT]):\n",
    "                    for c in range(filter_shape[WIDTH]):\n",
    "                        val += get_val(row + r, col + c, channel_idx) * f_weight\n",
    "                new_channel.append(val)\n",
    "                \n",
    "        new_channel = np.array(new_channel).reshape(new_channel_shape)\n",
    "        out.append(new_channel)\n",
    "                        \n",
    "        \n",
    "    out = np.stack(out, axis=-1)\n",
    "    out = out.reshape((1, out.shape[0], out.shape[1], out.shape[2]))\n",
    "    print('final shape:', out.shape)\n",
    "    return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(input_data, squeeze_dims):\n",
    "    print('********DOING SQUEEZE*********')\n",
    "    print('squeeze dims:', squeeze_dims)\n",
    "    print('og shape:', input_data.shape)\n",
    "    \n",
    "    out = input_data\n",
    "    for dim in sorted(squeeze_dims)[::-1]:\n",
    "        out = np.squeeze(out, axis=dim)\n",
    "    \n",
    "    print('final shape:', out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatbuffers as fb\n",
    "from tflite import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model stuf\n",
    "buf = open('mobilenet_v1_1.0_224.tflite', 'rb').read()\n",
    "buf = bytearray(buf)\n",
    "\n",
    "mobilenet = Model.GetRootAsModel(buf, 0)\n",
    "\n",
    "sub = mobilenet.Subgraphs(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONV2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_data, \n",
    "           filter_weights,\n",
    "           bias_weights=None,\n",
    "           stride_h=1, \n",
    "           stride_w=1, \n",
    "           dilate_h=1, \n",
    "           dilate_w=1, \n",
    "           pad_str='VALID', \n",
    "          ):\n",
    "    \n",
    "    padding = get_padding(pad_str, filter_weights.shape, input_data.shape, stride_h, stride_w, dilate_h, dilate_w)\n",
    "\n",
    "    # display stuff and make sure it's correct\n",
    "    print('********DOING CONV2D********')\n",
    "    print('input shape:', input_data.shape)\n",
    "    print('filter shape:', filter_weights.shape)\n",
    "    print('stride_h:', stride_h)\n",
    "    print('stride_w:', stride_w)\n",
    "    print('dilate_h_factor:', dilate_h)\n",
    "    print('dilate_w_factor:', dilate_w)\n",
    "    print('padding:', pad_str, padding)\n",
    "\n",
    "    my_im2col = im2col(input_data, \n",
    "                       filter_weights.shape, \n",
    "                       stride_h=stride_h,\n",
    "                       stride_w=stride_w, \n",
    "                       dilate_h=dilate_h, \n",
    "                       dilate_w=dilate_w, \n",
    "                       pad=padding\n",
    "                      )\n",
    "    \n",
    "#     print('im2col')\n",
    "#     print(my_im2col)\n",
    "\n",
    "    # matrix mult :\n",
    "    out = (filter_weights.reshape((filter_weights.shape[0], -1)) @ my_im2col).transpose()\n",
    "    shape = get_final_shape(input_data.shape, filter_weights.shape, pad_str, stride_h=stride_h, stride_w=stride_w)\n",
    "    \n",
    "    out = out.reshape((input_data.shape[0], shape[0], shape[1], filter_weights.shape[0]))\n",
    "\n",
    "    print('output shape:', out.shape)\n",
    "    if bias_weights is not None:\n",
    "        out = np.add(out, bias_weights)\n",
    "    return out\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(tensor, activation_str):\n",
    "    if activation_str == 'NONE':\n",
    "        return tensor\n",
    "    elif activation_str == 'RELU6':\n",
    "        return relu6(tensor)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "def relu6(tensor):\n",
    "    return np.minimum(np.maximum(tensor, 0), 6)\n",
    "\n",
    "def softmax(input_data, beta=1):\n",
    "    print('*******DOING SOFTMAX********')\n",
    "    print('beta:', beta)\n",
    "    \n",
    "    x = input_data\n",
    "    x = x - x.max(axis=None, keepdims=True)\n",
    "    y = np.exp(x)\n",
    "    return y / y.sum(axis=None, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conv_or_pool(options_type):\n",
    "    return options_type == BuiltinOptions.Conv2DOptions or options_type == BuiltinOptions.DepthwiseConv2DOptions or options_type == BuiltinOptions.Pool2DOptions\n",
    "        \n",
    "def get_correct_option_type(op):\n",
    "    op_type = op.BuiltinOptionsType()\n",
    "    if op_type == BuiltinOptions.Conv2DOptions:\n",
    "        return Conv2DOptions()\n",
    "    \n",
    "    elif op_type == BuiltinOptions.DepthwiseConv2DOptions:\n",
    "        return DepthwiseConv2DOptions()\n",
    "    \n",
    "    elif op_type == BuiltinOptions.Pool2DOptions:\n",
    "        return Pool2DOptions()\n",
    "    \n",
    "    elif op_type == BuiltinOptions.SqueezeOptions:\n",
    "        return SqueezeOptions()\n",
    "    \n",
    "    elif op_type == BuiltinOptions.SoftmaxOptions:\n",
    "        return SoftmaxOptions()\n",
    "    \n",
    "    return 'broke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_layer(layer, input_data):\n",
    "    print('layer', layer)\n",
    "    op = sub.Operators(layer)\n",
    "    out = 0\n",
    "    \n",
    "    # constant things again\n",
    "    filters_idx = op.Inputs(1)\n",
    "    bias_idx = op.Inputs(2)\n",
    "    padding_to_str = {Padding.SAME: 'SAME', Padding.VALID: 'VALID'}\n",
    "    activation_to_str = {ActivationFunctionType.NONE: 'NONE', ActivationFunctionType.RELU: 'RELU', ActivationFunctionType.RELU_N1_TO_1: 'RELU_N1_TO_1', ActivationFunctionType.RELU6: 'RELU6', ActivationFunctionType.TANH: 'TANH', ActivationFunctionType.SIGN_BIT: 'SIGN_BIT'}\n",
    "\n",
    "    options = get_correct_option_type(op) \n",
    "        \n",
    "    union = op.BuiltinOptions()\n",
    "    options.Init(union.Bytes, union.Pos)\n",
    "\n",
    "    # convolutions\n",
    "    if is_conv_or_pool(op.BuiltinOptionsType()):\n",
    "        \n",
    "        pad_str = padding_to_str[options.Padding()]\n",
    "        activation_str = activation_to_str[options.FusedActivationFunction()]\n",
    "\n",
    "        stride_h = options.StrideH()\n",
    "        stride_w = options.StrideW()\n",
    "        \n",
    "        \n",
    "        if op.BuiltinOptionsType() == BuiltinOptions.Conv2DOptions:\n",
    "            \n",
    "            filter_shape = tuple(sub.Tensors(filters_idx).ShapeAsNumpy())\n",
    "            bias_weights = np.frombuffer(mobilenet.Buffers(sub.Tensors(bias_idx).Buffer()).DataAsNumpy(), dtype=np.float32)\n",
    "            filter_weights = np.frombuffer(mobilenet.Buffers(sub.Tensors(filters_idx).Buffer()).DataAsNumpy(), dtype=np.float32).reshape(filter_shape)\n",
    "\n",
    "            dilate_h = options.DilationHFactor()\n",
    "            dilate_w = options.DilationWFactor()\n",
    "        \n",
    "            out = conv2d(input_data,\n",
    "                         filter_weights,\n",
    "                         bias_weights, \n",
    "                         stride_h=stride_h, \n",
    "                         stride_w=stride_w, \n",
    "                         dilate_h=dilate_h, \n",
    "                         dilate_w=dilate_w, \n",
    "                         pad_str=pad_str\n",
    "                        )\n",
    "        elif op.BuiltinOptionsType() == BuiltinOptions.DepthwiseConv2DOptions:\n",
    "            \n",
    "            \n",
    "            filter_shape = tuple(sub.Tensors(filters_idx).ShapeAsNumpy())\n",
    "            bias_weights = np.frombuffer(mobilenet.Buffers(sub.Tensors(bias_idx).Buffer()).DataAsNumpy(), dtype=np.float32)\n",
    "            filter_weights = np.frombuffer(mobilenet.Buffers(sub.Tensors(filters_idx).Buffer()).DataAsNumpy(), dtype=np.float32).reshape(filter_shape)\n",
    "\n",
    "            depth_mult = options.DepthMultiplier()\n",
    "            dilate_h = options.DilationHFactor()\n",
    "            dilate_w = options.DilationWFactor()\n",
    "        \n",
    "            out = depthwise_conv(input_data,\n",
    "                                 filter_weights,\n",
    "                                 bias_weights, \n",
    "                                 stride_h=stride_h, \n",
    "                                 stride_w=stride_w, \n",
    "                                 dilate_h=dilate_h, \n",
    "                                 dilate_w=dilate_w, \n",
    "                                 pad_str=pad_str,\n",
    "                                 depth_mult=depth_mult\n",
    "                                )\n",
    "        else:\n",
    "            f_shape = (options.FilterHeight(), options.FilterWidth())\n",
    "            \n",
    "            out = avg_pool(input_data, \n",
    "                           f_shape, \n",
    "                           stride_h=stride_h, \n",
    "                           stride_w=stride_w, \n",
    "                           pad_str=pad_str, \n",
    "                          )\n",
    "        \n",
    "        print('activation:', activation_str)\n",
    "        out = activation(out, activation_str)\n",
    "    elif op.BuiltinOptionsType() == BuiltinOptions.SqueezeOptions:\n",
    "        dims = options.SqueezeDimsAsNumpy()\n",
    "        \n",
    "        out = squeeze(input_data,\n",
    "                     dims)\n",
    "        \n",
    "    elif op.BuiltinOptionsType() == BuiltinOptions.SoftmaxOptions:\n",
    "        out = softmax(input_data)\n",
    "        \n",
    "    else:\n",
    "         print('!!!!!!!NOT IMPLEMENTED!!!!!!!!')\n",
    "        \n",
    "    print('*' * 30)\n",
    "    print()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 224, 224, 3)\n",
      "filter shape: (32, 3, 3, 3)\n",
      "stride_h: 2\n",
      "stride_w: 2\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 0, 1, 0]\n",
      "output shape: (1, 112, 112, 32)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 1\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 112, 112, 32)\n",
      "filter shape: (1, 3, 3, 32)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (112, 112)\n",
      "final shape: (1, 112, 112, 32)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 2\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 112, 112, 32)\n",
      "filter shape: (64, 1, 1, 32)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 112, 112, 64)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 3\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 112, 112, 64)\n",
      "filter shape: (1, 3, 3, 64)\n",
      "stride_h: 2\n",
      "stride_w: 2\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 0, 1, 0]\n",
      "depth mult: 1\n",
      "new channel shape: (56, 56)\n",
      "final shape: (1, 56, 56, 64)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 4\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 56, 56, 64)\n",
      "filter shape: (128, 1, 1, 64)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 56, 56, 128)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 5\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 56, 56, 128)\n",
      "filter shape: (1, 3, 3, 128)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (56, 56)\n",
      "final shape: (1, 56, 56, 128)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 6\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 56, 56, 128)\n",
      "filter shape: (128, 1, 1, 128)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 56, 56, 128)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 7\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 56, 56, 128)\n",
      "filter shape: (1, 3, 3, 128)\n",
      "stride_h: 2\n",
      "stride_w: 2\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 0, 1, 0]\n",
      "depth mult: 1\n",
      "new channel shape: (28, 28)\n",
      "final shape: (1, 28, 28, 128)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 8\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 28, 28, 128)\n",
      "filter shape: (256, 1, 1, 128)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 28, 28, 256)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 9\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 28, 28, 256)\n",
      "filter shape: (1, 3, 3, 256)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (28, 28)\n",
      "final shape: (1, 28, 28, 256)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 10\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 28, 28, 256)\n",
      "filter shape: (256, 1, 1, 256)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 28, 28, 256)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 11\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 28, 28, 256)\n",
      "filter shape: (1, 3, 3, 256)\n",
      "stride_h: 2\n",
      "stride_w: 2\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 0, 1, 0]\n",
      "depth mult: 1\n",
      "new channel shape: (14, 14)\n",
      "final shape: (1, 14, 14, 256)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 12\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 14, 14, 256)\n",
      "filter shape: (512, 1, 1, 256)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 13\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (1, 3, 3, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (14, 14)\n",
      "final shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 14\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (512, 1, 1, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 15\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (1, 3, 3, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (14, 14)\n",
      "final shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 16\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (512, 1, 1, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 17\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (1, 3, 3, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (14, 14)\n",
      "final shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 18\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (512, 1, 1, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 19\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (1, 3, 3, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (14, 14)\n",
      "final shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 20\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (512, 1, 1, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 21\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (1, 3, 3, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (14, 14)\n",
      "final shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 22\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (512, 1, 1, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 14, 14, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 23\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 14, 14, 512)\n",
      "filter shape: (1, 3, 3, 512)\n",
      "stride_h: 2\n",
      "stride_w: 2\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 0, 1, 0]\n",
      "depth mult: 1\n",
      "new channel shape: (7, 7)\n",
      "final shape: (1, 7, 7, 512)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 24\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 7, 7, 512)\n",
      "filter shape: (1024, 1, 1, 512)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 7, 7, 1024)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 25\n",
      "*****DOING DEPTHWISE CONV*****\n",
      "input shape: (1, 7, 7, 1024)\n",
      "filter shape: (1, 3, 3, 1024)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [1, 1, 1, 1]\n",
      "depth mult: 1\n",
      "new channel shape: (7, 7)\n",
      "final shape: (1, 7, 7, 1024)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 26\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 7, 7, 1024)\n",
      "filter shape: (1024, 1, 1, 1024)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 7, 7, 1024)\n",
      "activation: RELU6\n",
      "******************************\n",
      "\n",
      "layer 27\n",
      "********DOING AVG POOL********\n",
      "input shape: (1, 7, 7, 1024)\n",
      "filter shape: (1, 7, 7, 1024)\n",
      "stride_h: 2\n",
      "stride_w: 2\n",
      "padding: VALID [0, 0, 0, 0]\n",
      "new channel shape: (1, 1)\n",
      "final shape: (1, 1, 1, 1024)\n",
      "activation: NONE\n",
      "******************************\n",
      "\n",
      "layer 28\n",
      "********DOING CONV2D********\n",
      "input shape: (1, 1, 1, 1024)\n",
      "filter shape: (1001, 1, 1, 1024)\n",
      "stride_h: 1\n",
      "stride_w: 1\n",
      "dilate_h_factor: 1\n",
      "dilate_w_factor: 1\n",
      "padding: SAME [0, 0, 0, 0]\n",
      "output shape: (1, 1, 1, 1001)\n",
      "activation: NONE\n",
      "******************************\n",
      "\n",
      "layer 29\n",
      "********DOING SQUEEZE*********\n",
      "squeeze dims: [1 2]\n",
      "og shape: (1, 1, 1, 1001)\n",
      "final shape: (1, 1001)\n",
      "******************************\n",
      "\n",
      "layer 30\n",
      "*******DOING SOFTMAX********\n",
      "beta: 1\n",
      "******************************\n",
      "\n",
      "(1, 1001)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('cat_224.jpg')\n",
    "data = np.array(img).reshape((1,224,224,3)) / 255\n",
    "\n",
    "num_layers = sub.OperatorsLength()\n",
    "for i in range(num_layers):\n",
    "    data = do_layer(i, data)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_labels():\n",
    "    with open('imagenet_labels.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            s = line.split(':')[1]\n",
    "            s = s.replace('\\n', '')\n",
    "            s = s.replace(\"'\", '')\n",
    "            s = s[1:-1]\n",
    "            labels.append(s)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_imagenet_labels()\n",
    "\n",
    "# for i, label in enumerate(labels):\n",
    "#     print(i, ':', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454 : bookshop, bookstore, bookstall\n",
      "783 : screw\n",
      "282 : tiger cat\n",
      "286 : cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\n",
      "283 : Persian cat\n"
     ]
    }
   ],
   "source": [
    "sorted_idxs = np.argsort(data).reshape(-1)\n",
    "\n",
    "for idx in sorted_idxs[-5:]:\n",
    "    print(idx, ':', labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
